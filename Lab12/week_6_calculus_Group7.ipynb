{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matgonzalez23/MetNumUN2022I/blob/main/Lab12/week_6_calculus_Group7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Grupo 7**"
      ],
      "metadata": {
        "id": "emDh0zz9p3fl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Harold Velazco Ayala\n",
        "*   Mateo González Mogollón\n",
        "*   Andrés Felipe López Gutiérrez\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zq7fYV5Bp74G"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVOJ8o0-YduW"
      },
      "source": [
        "# Part I. One-sided finite differences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBDUlz2iYdub"
      },
      "source": [
        "Write a function, `deriv`, which computes a derivative of its argument at a given point, $x$, using a one-sided finite difference rule with a given step side $h$, with the approximation order of $O(h^2)$. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "rYXh0URrYduc"
      },
      "outputs": [],
      "source": [
        "def deriv(f, x, h):\n",
        "    \"\"\" Compute a derivative of `f` at point `x` with step size `h`.\n",
        "    \n",
        "    Compute the derivative using the one-sided rule of the approximation order of $O(h^2)$.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    f : callable\n",
        "        The function to differentiate\n",
        "    x : float\n",
        "        The point to compute the derivative at.\n",
        "    h : float\n",
        "        The step size for the finite different rule.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    fder : derivative of f(x) at point x using the step size h.\n",
        "    \"\"\"\n",
        "    # ... ENTER YOUR CODE HERE ...\n",
        "    x1 = x + h\n",
        "    dx = x1 - x\n",
        "    df = f(x1) - f(x)\n",
        "\n",
        "    return df / dx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZwB-mJ_Ydue"
      },
      "source": [
        "#### Test I.1\n",
        "\n",
        "Test your function on a simple test case: differentiate $f(x) = x^3$ at $x=0$. Comment on whether your results are consistent with the expected value of $f'(x) = 0$ and on an expected scaling with $h\\to 0$.\n",
        "\n",
        " (10% of the total grade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5SA5migYdue",
        "outputId": "cd8740d8-a6fd-4775-b1d1-c8ee4d90e35a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.010000 --  0.0001\n",
            "0.001000 --   1e-06\n",
            "0.000100 --   1e-08\n",
            "0.000010 --   1e-10\n"
          ]
        }
      ],
      "source": [
        "x = 0\n",
        "for h in [1e-2, 1e-3, 1e-4, 1e-5]:\n",
        "    err = deriv(lambda x: x**3, x, h)\n",
        "    print(\"%5f -- %7.4g\" % (h, err))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOVj2onJYduf"
      },
      "source": [
        " ... ENTER YOUR COMMENTS HERE ...\n",
        " \n",
        " As h (step size) decrease, the error term decreases as well"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWHHUXynYduf"
      },
      "source": [
        "### Test I.2\n",
        "\n",
        "Now use a slightly more complicated function, $f(x) = x^2 \\log{x}$, evaluate the derivative at $x=1$ using your one-sided rule and a two-point one-sided rule. Roughly estimate the value of $h$ where the error stops decreasing, for these two schemes. \n",
        "(15% of the total grade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "tYv5dAF-Yduf"
      },
      "outputs": [],
      "source": [
        "from math import log\n",
        "\n",
        "def f(x):\n",
        "    return x**2 * log(x)\n",
        "    \n",
        "def fder(x):\n",
        "    return x * (2.*log(x) + 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "-QdDsltBYdug",
        "outputId": "0b1f525e-ded1-45b2-d2d2-2cbec9e0a848"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-85cbd65e1b82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mderiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%5f -- %7.4g\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-c3c17b32ad9a>\u001b[0m in \u001b[0;36mderiv\u001b[0;34m(f, x, h)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mdx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-3dcb5ac8f36d>\u001b[0m in \u001b[0;36mf\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: math domain error"
          ]
        }
      ],
      "source": [
        "# ... ENTER YOUR CODE HERE ...\n",
        "x = 0\n",
        "for h in [1e-2, 1e-3, 1e-4, 1e-5]:\n",
        "    err = deriv(f, x, h) - fder(x)\n",
        "    print(\"%5f -- %7.4g\" % (h, err))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYFUlyRrYduh"
      },
      "source": [
        "### Test I.3 \n",
        "\n",
        "Now try differentiating $x^2 \\log(x)$ at $x=0$. Use the three-point one-sided rule. Note that to evaluate the function at zero, you need to special-case this value. Check the scaling of the error with $h$, explain your results. \n",
        "(25% of the total grade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPYFgUmEYduh",
        "outputId": "42d980d3-3124-4fdc-c803-c4fda4ab8039"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.010000 -- -0.04605\n",
            "0.001000 -- -0.006908\n",
            "0.000100 -- -0.000921\n",
            "0.000010 -- -0.0001151\n"
          ]
        }
      ],
      "source": [
        "def f(x):\n",
        "    if x == 0:\n",
        "        # the limit of $x^2 log(x)$ at $x-> 0$ is zero, even though log(x) is undefined at x=0\n",
        "        return 0.0\n",
        "    else:\n",
        "        return x**2 * log(x)\n",
        "    \n",
        "def fder(x):\n",
        "    if x == 0:\n",
        "        return 0.0\n",
        "    else:\n",
        "        return x*(2*log(x) + 1)\n",
        "\n",
        "x = 0\n",
        "for h in [1e-2, 1e-3, 1e-4, 1e-5]:\n",
        "    err = deriv(f, x, h) - fder(x)\n",
        "    print(\"%5f -- %7.4g\" % (h, err))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkBbhix5Ydui"
      },
      "source": [
        "... ENTER YOUR EXPLANATION HERE ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVfs2cw6Ydui"
      },
      "source": [
        "# Part II. Midpoint rule "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIfGXriZYdui"
      },
      "source": [
        "Write a function which computes a definite integral using the midpoint rule up to a given error, $\\epsilon$. Estimate the error by comparing the estimates of the integral at $N$ and $2N$ elementary intervals. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "-LTejfyZYdui"
      },
      "outputs": [],
      "source": [
        "def midpoint_rule(func, a, b, eps):\n",
        "    \"\"\" Calculate the integral of f from a to b using the midpoint rule.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    func : callable\n",
        "        The function to integrate.\n",
        "    a : float\n",
        "        The lower limit of integration.\n",
        "    b : float\n",
        "        The upper limit of integration.\n",
        "    eps : float\n",
        "        The target accuracy of the estimate.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    integral : float\n",
        "        The estimate of $\\int_a^b f(x) dx$.\n",
        "    \"\"\"\n",
        "    # ... ENTER YOUR CODE HERE ...\n",
        "    h = float(b-a)/eps\n",
        "    result = 0\n",
        "    for i in range(eps):\n",
        "        result += func((a + h/2.0) + i*h)\n",
        "    result *= h\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_kG2zxDYduj"
      },
      "source": [
        "### Test II.1\n",
        "\n",
        "Test your midpoint rule on a simple integral, which you can calculate by paper and pencil.\n",
        "\n",
        "Compare the rate of convergence to the expected $O(N^{-2})$ scaling by studying the number of intervals required for a given accuracy $\\epsilon$.\n",
        "\n",
        "Compare the numerical results to the value you calculated by hand. Does the deviation agree with your estimate of the numerical error?\n",
        "(20% of the total grade)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from math import exp\n",
        "\n",
        "g = lambda y: exp(-y**2)\n",
        "a = 0\n",
        "b = 2\n",
        "\n",
        "for i in range(1, 21):\n",
        "    n = 2**i\n",
        "    m = midpoint_rule(g, a, b, n)\n",
        "    print ('%7d %.16f' % (n, m))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FT6ZZikJj4IS",
        "outputId": "2d1a34aa-ff16-4006-e223-2efdef7675a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      2 0.8842000076332692\n",
            "      4 0.8827889485397279\n",
            "      8 0.8822686991994210\n",
            "     16 0.8821288703366458\n",
            "     32 0.8820933014203766\n",
            "     64 0.8820843709743319\n",
            "    128 0.8820821359746071\n",
            "    256 0.8820815770754198\n",
            "    512 0.8820814373412922\n",
            "   1024 0.8820814024071774\n",
            "   2048 0.8820813936736116\n",
            "   4096 0.8820813914902204\n",
            "   8192 0.8820813909443684\n",
            "  16384 0.8820813908079066\n",
            "  32768 0.8820813907737911\n",
            "  65536 0.8820813907652575\n",
            " 131072 0.8820813907631487\n",
            " 262144 0.8820813907625702\n",
            " 524288 0.8820813907624605\n",
            "1048576 0.8820813907624268\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4pdqubVYduj"
      },
      "source": [
        "### Test II.2\n",
        "\n",
        "Now use your midpoint rule to compute the value of\n",
        "\n",
        "$$\n",
        "\\int_0^1\\! \\frac{\\sin{\\sqrt{x}}}{x}\\, dx\n",
        "$$\n",
        "\n",
        "up to a predefined accuracy of $\\epsilon=10^{-4}$.\n",
        "\n",
        "Note that the integral contains an integrable singularity at the lower limit. Do calculations two ways: first, do a straightforward computation; next, subtract the singularity. Compare the number of iterations required to achieve the accuracy of $\\epsilon$.\n",
        "\n",
        "(30% of the total grade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBhG54D2Yduk",
        "outputId": "a84b980d-73dd-42dc-86d9-7249579a1958"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "a = 0.1; b = 0.2; expected = 0.3\n",
        "computed = a + b\n",
        "diff = abs(expected - computed)\n",
        "tol = 1E-15\n",
        "diff < tol"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "week_6_calculus_Group7.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}